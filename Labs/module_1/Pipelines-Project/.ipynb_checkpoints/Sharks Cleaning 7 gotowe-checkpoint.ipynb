{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Importing file sharks and making a copy:\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "os.chdir('C:/Users/Kasia/TEST/806_Repo/Labs/module_1/Pipelines-Project/204_47432_compressed_attacks')\n",
    "sharks=pd.read_csv(\"attacks.csv\", encoding='latin-1')\n",
    "data = sharks.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>25-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Boating</td>\n",
       "      <td>USA</td>\n",
       "      <td>California</td>\n",
       "      <td>Oceanside, San Diego County</td>\n",
       "      <td>Paddling</td>\n",
       "      <td>Julie Wolfe</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>White shark</td>\n",
       "      <td>R. Collier, GSAF</td>\n",
       "      <td>2018.06.25-Wolfe.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>2018.06.25</td>\n",
       "      <td>6303.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>18-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>St. Simon Island, Glynn County</td>\n",
       "      <td>Standing</td>\n",
       "      <td>Adyson McNeely</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.18-McNeely.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>2018.06.18</td>\n",
       "      <td>6302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>09-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>USA</td>\n",
       "      <td>Hawaii</td>\n",
       "      <td>Habush, Oahu</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>John Denges</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>K.McMurray, TrackingSharks.com</td>\n",
       "      <td>2018.06.09-Denges.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>2018.06.09</td>\n",
       "      <td>6301.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>08-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Arrawarra Headland</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>male</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>2 m shark</td>\n",
       "      <td>B. Myatt, GSAF</td>\n",
       "      <td>2018.06.08-Arrawarra.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>2018.06.08</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>04-Jun-2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>MEXICO</td>\n",
       "      <td>Colima</td>\n",
       "      <td>La Ticla</td>\n",
       "      <td>Free diving</td>\n",
       "      <td>Gustavo Ramos</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 3m</td>\n",
       "      <td>A .Kipper</td>\n",
       "      <td>2018.06.04-Ramos.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>2018.06.04</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Case Number         Date    Year        Type    Country             Area  \\\n",
       "0  2018.06.25  25-Jun-2018  2018.0     Boating        USA       California   \n",
       "1  2018.06.18  18-Jun-2018  2018.0  Unprovoked        USA          Georgia   \n",
       "2  2018.06.09  09-Jun-2018  2018.0     Invalid        USA           Hawaii   \n",
       "3  2018.06.08  08-Jun-2018  2018.0  Unprovoked  AUSTRALIA  New South Wales   \n",
       "4  2018.06.04  04-Jun-2018  2018.0    Provoked     MEXICO           Colima   \n",
       "\n",
       "                         Location     Activity             Name Sex   ...  \\\n",
       "0     Oceanside, San Diego County     Paddling      Julie Wolfe    F  ...   \n",
       "1  St. Simon Island, Glynn County     Standing  Adyson McNeely     F  ...   \n",
       "2                    Habush, Oahu      Surfing      John Denges    M  ...   \n",
       "3              Arrawarra Headland      Surfing             male    M  ...   \n",
       "4                        La Ticla  Free diving   Gustavo Ramos     M  ...   \n",
       "\n",
       "          Species           Investigator or Source                       pdf  \\\n",
       "0      White shark                R. Collier, GSAF      2018.06.25-Wolfe.pdf   \n",
       "1              NaN  K.McMurray, TrackingSharks.com    2018.06.18-McNeely.pdf   \n",
       "2              NaN  K.McMurray, TrackingSharks.com     2018.06.09-Denges.pdf   \n",
       "3        2 m shark                  B. Myatt, GSAF  2018.06.08-Arrawarra.pdf   \n",
       "4  Tiger shark, 3m                       A .Kipper      2018.06.04-Ramos.pdf   \n",
       "\n",
       "                                        href formula  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                href Case Number.1  \\\n",
       "0  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.25   \n",
       "1  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.18   \n",
       "2  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.09   \n",
       "3  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.08   \n",
       "4  http://sharkattackfile.net/spreadsheets/pdf_di...    2018.06.04   \n",
       "\n",
       "  Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "0    2018.06.25         6303.0         NaN         NaN  \n",
       "1    2018.06.18         6302.0         NaN         NaN  \n",
       "2    2018.06.09         6301.0         NaN         NaN  \n",
       "3    2018.06.08         6300.0         NaN         NaN  \n",
       "4    2018.06.04         6299.0         NaN         NaN  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Examining data:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25723, 24)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
       "       'Activity', 'Name', 'Sex ', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
       "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
       "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
       "       'Unnamed: 23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No injury to occupant, outrigger canoe and paddle damaged',\n",
       "       'Minor injury to left thigh',\n",
       "       'Injury to left lower leg from surfboard skeg', ...,\n",
       "       'FATAL, leg stripped of flesh  ',\n",
       "       'FATAL, knocked overboard by tail of shark & carried off by shark ',\n",
       "       'FATAL. \"Shark bit him in half, carrying away the lower extremities\" '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking what unique values I have in each column to get more idea of what I have in my data:\n",
    "data[\"Injury\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n3. After checking what my data looks like, I am defining my purpose of cleaning the data:\\n\\nTravel agency is studying about best locations to organize water sports escapades.\\nThey are asking me:\\n- which countries are to avoid when it comes to shark attacks danger;\\n- the risk that the shark attack will be fatal;\\n- if there is any seasonality in shark attacks, so they could avoid certain months.\\n\\nSo to my study, the most important columns are:\\nCountry, Year - these cannot be nan\\nFatal, Date - these, even if nan, I keep, bc they still give me info that there was an attack in specyfic country\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "3. After checking what my data looks like, I am defining my purpose of cleaning the data:\n",
    "\n",
    "Travel agency is studying about best locations to organize water sports escapades.\n",
    "They are asking me:\n",
    "- which countries are to avoid when it comes to shark attacks danger;\n",
    "- the risk that the shark attack will be fatal;\n",
    "- if there is any seasonality in shark attacks, so they could avoid certain months.\n",
    "\n",
    "So to my study, the most important columns are:\n",
    "Country, Year - these cannot be nan\n",
    "Fatal, Date - these, even if nan, I keep, bc they still give me info that there was an attack in specyfic country\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. I decided to drop columns at the end of the pricess, bc even unnecessary columns I might need to clean necessary columns.\n",
    "# ( I have learnt it hard way ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "25718     True\n",
       "25719     True\n",
       "25720     True\n",
       "25721     True\n",
       "25722    False\n",
       "Length: 25723, dtype: bool"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. I will check if there are duplicated rows:\n",
    "\n",
    "#data.duplicated(subset=[\"Date\",\"Name\",\"Location\", \"Injury\",\"Time\"])\n",
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6312, 24)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Apparently there are exact duplicates, I will get rid of them:\n",
    "data = data.drop_duplicates()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. If I understand well, there were 21k rows duplicated??? I hope I understand well..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018., 2017.,   nan, 2016., 2015., 2014., 2013., 2012., 2011.,\n",
       "       2010., 2009., 2008., 2007., 2006., 2005., 2004., 2003., 2002.,\n",
       "       2001., 2000., 1999., 1998., 1997., 1996., 1995., 1984., 1994.,\n",
       "       1993., 1992., 1991., 1990., 1989., 1969., 1988., 1987., 1986.,\n",
       "       1985., 1983., 1982., 1981., 1980., 1979., 1978., 1977., 1976.,\n",
       "       1975., 1974., 1973., 1972., 1971., 1970., 1968., 1967., 1966.,\n",
       "       1965., 1964., 1963., 1962., 1961., 1960., 1959., 1958., 1957.,\n",
       "       1956., 1955., 1954., 1953., 1952., 1951., 1950., 1949., 1948.,\n",
       "       1848., 1947., 1946., 1945., 1944., 1943., 1942., 1941., 1940.,\n",
       "       1939., 1938., 1937., 1936., 1935., 1934., 1933., 1932., 1931.,\n",
       "       1930., 1929., 1928., 1927., 1926., 1925., 1924., 1923., 1922.,\n",
       "       1921., 1920., 1919., 1918., 1917., 1916., 1915., 1914., 1913.,\n",
       "       1912., 1911., 1910., 1909., 1908., 1907., 1906., 1905., 1904.,\n",
       "       1903., 1902., 1901., 1900., 1899., 1898., 1897., 1896., 1895.,\n",
       "       1894., 1893., 1892., 1891., 1890., 1889., 1888., 1887., 1886.,\n",
       "       1885., 1884., 1883., 1882., 1881., 1880., 1879., 1878., 1877.,\n",
       "       1876., 1875., 1874., 1873., 1872., 1871., 1870., 1869., 1868.,\n",
       "       1867., 1866., 1865., 1864., 1863., 1862., 1861., 1860., 1859.,\n",
       "       1858., 1857., 1856., 1855., 1853., 1852., 1851., 1850., 1849.,\n",
       "       1847., 1846., 1845., 1844., 1842., 1841., 1840., 1839., 1837.,\n",
       "       1836., 1835., 1834., 1832., 1831., 1830., 1829., 1828., 1827.,\n",
       "       1826., 1825., 1823., 1822., 1819., 1818., 1817., 1816., 1815.,\n",
       "       1812., 1811., 1810., 1808., 1807., 1805., 1804., 1803., 1802.,\n",
       "       1801., 1800., 1797., 1792., 1791., 1788., 1787., 1786., 1785.,\n",
       "       1784., 1783., 1780., 1779., 1776., 1771., 1767., 1764., 1758.,\n",
       "       1753., 1751., 1749., 1755., 1748., 1742., 1738., 1733., 1723.,\n",
       "       1721., 1703., 1700., 1642., 1638., 1637., 1617., 1595., 1580.,\n",
       "       1555., 1554., 1543.,  500.,   77.,    5.,    0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Checking my important columns for unique values\n",
    "data[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018., 2017.,   nan, 2016., 2015., 2014., 2013., 2012., 2011.,\n",
       "       2010., 2009., 2008., 2007., 2006., 2005., 2004., 2003., 2002.,\n",
       "       2001., 2000.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Will start with Year - it goes back to 1543:\n",
    "indexNames = data[data['Year'] < 2000].index\n",
    "data.drop(indexNames , inplace=True)\n",
    "data[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2018., 2017., 2016., 2015., 2014., 2013., 2012., 2011., 2010.,\n",
       "       2009., 2008., 2007., 2006., 2005., 2004., 2003., 2002., 2001.,\n",
       "       2000.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Year column is essential to me (the migration of sharks every 20 years), so I will drop nans:\n",
    "data.dropna(subset = [\"Year\"], inplace=True)\n",
    "data[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2078, 24)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', nan, 'M', 'UNKNOWN', '2017'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. Checking Fatality column:\n",
    "data[\"Fatal (Y/N)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-0dbea2ab1270>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-0dbea2ab1270>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    data.[\"Fatal (Y/N)\"].unique()\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 12. Will clean values:\n",
    "data[\"Fatal (Y/N)\"] = data[\"Fatal (Y/N)\"].str.replace('M', 'N')\n",
    "data.[\"Fatal (Y/N)\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', nan, 'UNKNOWN', '2017'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. I constate that having spaces in col name is not a good thing, will rename this column first:\n",
    "data = data.rename(columns={'Fatal (Y/N)':'Fatality'})\n",
    "# 14. and clean the M/N:\n",
    "data[\"Fatality\"] = data[\"Fatality\"].str.replace('M', 'N')\n",
    "data.Fatality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N          1739\n",
       "Y           175\n",
       "UNKNOWN       2\n",
       "2017          1\n",
       "Name: Fatality, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15. \n",
    "data.Fatality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>2012.06.10</td>\n",
       "      <td>10-Jun-2012</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Provoked</td>\n",
       "      <td>ITALY</td>\n",
       "      <td>Sardinia</td>\n",
       "      <td>Muravera</td>\n",
       "      <td>Attempting to rescue an injured &amp; beached shark</td>\n",
       "      <td>Giorgio Zara</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Blue shark, 2.5m</td>\n",
       "      <td>D. Puddo, 6/11/2012</td>\n",
       "      <td>2012.06.10-Zara.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2012.06.10</td>\n",
       "      <td>2012.06.10</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Case Number         Date    Year      Type Country      Area  Location  \\\n",
       "786  2012.06.10  10-Jun-2012  2012.0  Provoked   ITALY  Sardinia  Muravera   \n",
       "\n",
       "                                            Activity          Name Sex   ...  \\\n",
       "786  Attempting to rescue an injured & beached shark  Giorgio Zara    M  ...   \n",
       "\n",
       "             Species  Investigator or Source                  pdf  \\\n",
       "786  Blue shark, 2.5m    D. Puddo, 6/11/2012  2012.06.10-Zara.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "786  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href Case Number.1  \\\n",
       "786  http://sharkattackfile.net/spreadsheets/pdf_di...    2012.06.10   \n",
       "\n",
       "    Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "786    2012.06.10         5517.0         NaN         NaN  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16. looks good, 3 values that is tempting to drop/leave them, but let s see if possible to correct them:\n",
    "# question in my head, shall i drop these 3 rows of nan or keep the for the sake of other info in the row?\n",
    "#I will keep them for now\n",
    "data.loc[data['Fatality'] == \"2017\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2013.09.08</td>\n",
       "      <td>08-Sep-2013</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>USA</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>St. Helena Island, Beaufort County</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WIS-TV, 9/9/2013</td>\n",
       "      <td>2013.09.08-St-Helena.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2013.09.08</td>\n",
       "      <td>2013.09.08</td>\n",
       "      <td>5679.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>2008.04.20.a</td>\n",
       "      <td>20-Apr-2008</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "      <td>New South Wales</td>\n",
       "      <td>Crescent Head</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jamie Adlington</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Tiger shark, 2.3m</td>\n",
       "      <td>T. Peake, GSAF</td>\n",
       "      <td>2008.04.20.a-Adlington.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2008.04.20.a</td>\n",
       "      <td>2008.04.20.a</td>\n",
       "      <td>5033.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Case Number         Date    Year        Type    Country  \\\n",
       "624     2013.09.08  08-Sep-2013  2013.0  Unprovoked        USA   \n",
       "1270  2008.04.20.a  20-Apr-2008  2008.0  Unprovoked  AUSTRALIA   \n",
       "\n",
       "                 Area                            Location Activity  \\\n",
       "624    South Carolina  St. Helena Island, Beaufort County      NaN   \n",
       "1270  New South Wales                       Crescent Head      NaN   \n",
       "\n",
       "                 Name Sex   ...            Species  Investigator or Source  \\\n",
       "624            female    F  ...                 NaN       WIS-TV, 9/9/2013   \n",
       "1270  Jamie Adlington    M  ...  Tiger shark, 2.3m          T. Peake, GSAF   \n",
       "\n",
       "                             pdf  \\\n",
       "624     2013.09.08-St-Helena.pdf   \n",
       "1270  2008.04.20.a-Adlington.pdf   \n",
       "\n",
       "                                           href formula  \\\n",
       "624   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "1270  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                   href Case Number.1  \\\n",
       "624   http://sharkattackfile.net/spreadsheets/pdf_di...    2013.09.08   \n",
       "1270  http://sharkattackfile.net/spreadsheets/pdf_di...  2008.04.20.a   \n",
       "\n",
       "     Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "624     2013.09.08         5679.0         NaN         NaN  \n",
       "1270  2008.04.20.a         5033.0         NaN         NaN  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16a\n",
    "data.loc[data['Fatality'] == \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y', 'UNKNOWN'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17. seems like 2017 was not fatal, lets correct it:\n",
    "data[\"Fatality\"] = data[\"Fatality\"].str.replace('2017', 'N')\n",
    "data['Fatality'] = data['Fatality'].fillna(\"UNKNOWN\")\n",
    "data.Fatality.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 17a\n",
    "# ok, looks good, but it wasnt piece of cake, been struggling with:\n",
    "#NameError: name 'nan' is not defined, imported numby but it didnt help, then was this:\n",
    "#TypeError: repl must be a string or callable\n",
    "# grrrrr, I will change my nan to UNKNOWN instead:\n",
    "#data['Fatality'] = data['Fatality'].fillna(\"UNKNOWN\")\n",
    "#data[\"Fatality\"] = data[\"Fatality\"].str.replace('','UNKNOWN')\n",
    "#data.Fatality.unique()\n",
    "#array(['UNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNNUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWN',\n",
    " #      'UNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNYUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWN',\n",
    "  #     'UNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNUUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNNUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNKUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNNUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNOUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNWUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWNNUNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWN',\n",
    "   #    'UNKNOWNUUNKNOWNNUNKNOWNKUNKNOWNNUNKNOWNOUNKNOWNWUNKNOWNNUNKNOWN'],\n",
    "    #  dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'MEXICO', 'BRAZIL', 'ENGLAND', 'SOUTH AFRICA',\n",
       "       'THAILAND', 'COSTA RICA', 'MALDIVES', 'BAHAMAS', 'NEW CALEDONIA',\n",
       "       'ECUADOR', 'MALAYSIA', 'LIBYA', nan, 'CUBA', 'MAURITIUS',\n",
       "       'NEW ZEALAND', 'SPAIN', 'SAMOA', 'SOLOMON ISLANDS', 'JAPAN',\n",
       "       'EGYPT', 'ST HELENA, British overseas territory', 'COMOROS',\n",
       "       'REUNION', 'FRENCH POLYNESIA', 'UNITED KINGDOM',\n",
       "       'UNITED ARAB EMIRATES', 'PHILIPPINES', 'INDONESIA', 'CHINA',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'Fiji', 'DOMINICAN REPUBLIC',\n",
       "       'CAYMAN ISLANDS', 'ARUBA', 'MOZAMBIQUE', 'FIJI', 'PUERTO RICO',\n",
       "       'ITALY', 'ATLANTIC OCEAN', 'GREECE', 'ST. MARTIN', 'FRANCE',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'NIGERIA', 'TONGA', 'SCOTLAND',\n",
       "       'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE', 'ANTIGUA', 'KENYA',\n",
       "       'RUSSIA', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)', 'AZORES',\n",
       "       'SOUTH KOREA', 'MALTA', 'VIETNAM', 'MADAGASCAR', 'PANAMA',\n",
       "       'SOMALIA', 'NEVIS', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL',\n",
       "       'YEMEN', 'GULF OF ADEN', 'Sierra Leone', 'ST. MAARTIN',\n",
       "       'GRAND CAYMAN', 'Seychelles', 'LIBERIA', 'VANUATU', 'MEXICO ',\n",
       "       'HONDURAS', 'VENEZUELA', 'SRI LANKA', ' TONGA', 'URUGUAY', 'INDIA',\n",
       "       'MICRONESIA', 'CARIBBEAN SEA', 'OKINAWA', 'TANZANIA'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 18. I will now work on Country column:\n",
    "data[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'MEXICO', 'BRAZIL', 'NUNITED KINGDOM',\n",
       "       'SOUTH AFRICA', 'THAILAND', 'COSTA RICA', 'MALDIVES', 'BAHAMAS',\n",
       "       'NEW CALEDONIA', 'ECUADOR', 'MALAYSIA', 'LIBYA', 'UNKNOWN', 'CUBA',\n",
       "       'MAURITIUS', 'NEW ZEALAND', 'SPAIN', 'SAMOA', 'SOLOMON ISLANDS',\n",
       "       'JAPAN', 'EGYPT', 'ST HELENA, BRITISH OVERSEAS TERRITORY',\n",
       "       'COMOROS', 'REUNION', 'FRENCH POLYNESIA', 'UNITED KINGDOM',\n",
       "       'UNITED ARAB EMIRATES', 'PHILIPPINES', 'INDONESIA', 'CHINA',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'FIJI', 'DOMINICAN REPUBLIC',\n",
       "       'CAYMAN ISLANDS', 'ARUBA', 'MOZAMBIQUE', 'PUERTO RICO', 'ITALY',\n",
       "       'ATLANTIC OCEAN', 'GREECE', 'ST. MARTIN', 'FRANCE',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'NIGERIA', 'TONGA', 'SCOTLAND',\n",
       "       'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE', 'ANTIGUA', 'KENYA',\n",
       "       'RUSSIA', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)', 'AZORES',\n",
       "       'SOUTH KOREA', 'MALTA', 'VIETNAM', 'MADAGASCAR', 'PANAMA',\n",
       "       'SOMALIA', 'NEVIS', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL',\n",
       "       'YEMEN', 'GULF OF ADEN', 'SIERRA LEONE', 'ST. MAARTIN',\n",
       "       'GRAND CAYMAN', 'LIBERIA', 'VANUATU', 'HONDURAS', 'VENEZUELA',\n",
       "       'SRI LANKA', 'URUGUAY', 'INDIA', 'MICRONESIA', 'CARIBBEAN SEA',\n",
       "       'OKINAWA', 'TANZANIA'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19. It seems pretty clean to me, I will only \n",
    "# - change nans na UNMKNOWN\n",
    "# - merge FIJI with Fiji\n",
    "# - merge England with United Kingdom (eventhough missing some information)\n",
    "data['Country'].fillna('UNKNOWN', inplace=True)\n",
    "data['Country'] = data['Country'].str.strip().str.upper()\n",
    "data[\"Country\"] = data[\"Country\"].str.replace('ENGLAND', 'NUNITED KINGDOM')\n",
    "data[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Type</th>\n",
       "      <th>Country</th>\n",
       "      <th>Area</th>\n",
       "      <th>Location</th>\n",
       "      <th>Activity</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>...</th>\n",
       "      <th>Species</th>\n",
       "      <th>Investigator or Source</th>\n",
       "      <th>pdf</th>\n",
       "      <th>href formula</th>\n",
       "      <th>href</th>\n",
       "      <th>Case Number.1</th>\n",
       "      <th>Case Number.2</th>\n",
       "      <th>original order</th>\n",
       "      <th>Unnamed: 22</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2017.11.13.R</td>\n",
       "      <td>Reported 13-Nov-2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>Unprovoked</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Surfing</td>\n",
       "      <td>Timur Yunusov</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>2017.11.13.R-Timur.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2017.11.13.R</td>\n",
       "      <td>2017.11.13.R</td>\n",
       "      <td>6241.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2014.08.00</td>\n",
       "      <td>Aug-2014</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Invalid</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sea disaster</td>\n",
       "      <td>Cuban refugees</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>Shark involvement not confirmed</td>\n",
       "      <td>Associated Press, 11/27/2014</td>\n",
       "      <td>2014.08.00-Cuban-refugees.pdf</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>http://sharkattackfile.net/spreadsheets/pdf_di...</td>\n",
       "      <td>2014.08.00</td>\n",
       "      <td>2014.08.00</td>\n",
       "      <td>5778.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Case Number                  Date    Year        Type  Country Area  \\\n",
       "62   2017.11.13.R  Reported 13-Nov-2017  2017.0  Unprovoked  UNKNOWN  NaN   \n",
       "525    2014.08.00              Aug-2014  2014.0     Invalid  UNKNOWN  NaN   \n",
       "\n",
       "    Location      Activity            Name Sex   ...  \\\n",
       "62       NaN       Surfing   Timur Yunusov    M  ...   \n",
       "525      NaN  Sea disaster  Cuban refugees    M  ...   \n",
       "\n",
       "                            Species         Investigator or Source  \\\n",
       "62                               NaN                     Instagram   \n",
       "525  Shark involvement not confirmed  Associated Press, 11/27/2014   \n",
       "\n",
       "                               pdf  \\\n",
       "62          2017.11.13.R-Timur.pdf   \n",
       "525  2014.08.00-Cuban-refugees.pdf   \n",
       "\n",
       "                                          href formula  \\\n",
       "62   http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "525  http://sharkattackfile.net/spreadsheets/pdf_di...   \n",
       "\n",
       "                                                  href Case Number.1  \\\n",
       "62   http://sharkattackfile.net/spreadsheets/pdf_di...  2017.11.13.R   \n",
       "525  http://sharkattackfile.net/spreadsheets/pdf_di...    2014.08.00   \n",
       "\n",
       "    Case Number.2 original order Unnamed: 22 Unnamed: 23  \n",
       "62   2017.11.13.R         6241.0         NaN         NaN  \n",
       "525    2014.08.00         5778.0         NaN         NaN  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 20. I will check how many nans we have and if we can find the Country by its Area or Location column.\n",
    "data.loc[data['Country'] == \"UNKNOWN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['USA', 'AUSTRALIA', 'MEXICO', 'BRAZIL', 'NUNITED KINGDOM',\n",
       "       'SOUTH AFRICA', 'THAILAND', 'COSTA RICA', 'MALDIVES', 'BAHAMAS',\n",
       "       'NEW CALEDONIA', 'ECUADOR', 'MALAYSIA', 'LIBYA', 'CUBA',\n",
       "       'MAURITIUS', 'NEW ZEALAND', 'SPAIN', 'SAMOA', 'SOLOMON ISLANDS',\n",
       "       'JAPAN', 'EGYPT', 'ST HELENA, BRITISH OVERSEAS TERRITORY',\n",
       "       'COMOROS', 'REUNION', 'FRENCH POLYNESIA', 'UNITED KINGDOM',\n",
       "       'UNITED ARAB EMIRATES', 'PHILIPPINES', 'INDONESIA', 'CHINA',\n",
       "       'COLUMBIA', 'CAPE VERDE', 'FIJI', 'DOMINICAN REPUBLIC',\n",
       "       'CAYMAN ISLANDS', 'ARUBA', 'MOZAMBIQUE', 'PUERTO RICO', 'ITALY',\n",
       "       'ATLANTIC OCEAN', 'GREECE', 'ST. MARTIN', 'FRANCE',\n",
       "       'PAPUA NEW GUINEA', 'TRINIDAD & TOBAGO', 'KIRIBATI', 'ISRAEL',\n",
       "       'DIEGO GARCIA', 'TAIWAN', 'JAMAICA', 'PALESTINIAN TERRITORIES',\n",
       "       'GUAM', 'SEYCHELLES', 'BELIZE', 'NIGERIA', 'TONGA', 'SCOTLAND',\n",
       "       'CANADA', 'CROATIA', 'SAUDI ARABIA', 'CHILE', 'ANTIGUA', 'KENYA',\n",
       "       'RUSSIA', 'TURKS & CAICOS', 'UNITED ARAB EMIRATES (UAE)', 'AZORES',\n",
       "       'SOUTH KOREA', 'MALTA', 'VIETNAM', 'MADAGASCAR', 'PANAMA',\n",
       "       'SOMALIA', 'NEVIS', 'BRITISH VIRGIN ISLANDS', 'NORWAY', 'SENEGAL',\n",
       "       'YEMEN', 'GULF OF ADEN', 'SIERRA LEONE', 'ST. MAARTIN',\n",
       "       'GRAND CAYMAN', 'LIBERIA', 'VANUATU', 'HONDURAS', 'VENEZUELA',\n",
       "       'SRI LANKA', 'URUGUAY', 'INDIA', 'MICRONESIA', 'CARIBBEAN SEA',\n",
       "       'OKINAWA', 'TANZANIA'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 21.We can drop these 2 rows:\n",
    "indexNames = data[data['Country'] == \"UNKNOWN\"].index\n",
    "data.drop(indexNames , inplace=True)\n",
    "data[\"Country\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 22. not sure if there is a point to change data type (?)\n",
    "display(data.Year.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 23. Area seems OK\n",
    "#data[\"Area\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>2076.0</td>\n",
       "      <td>2009.407996</td>\n",
       "      <td>5.272681</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2005.00</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original order</th>\n",
       "      <td>2076.0</td>\n",
       "      <td>5262.871387</td>\n",
       "      <td>599.952129</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>4743.75</td>\n",
       "      <td>5262.5</td>\n",
       "      <td>5782.25</td>\n",
       "      <td>6303.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean         std     min      25%     50%  \\\n",
       "Year            2076.0  2009.407996    5.272681  2000.0  2005.00  2010.0   \n",
       "original order  2076.0  5262.871387  599.952129  4225.0  4743.75  5262.5   \n",
       "\n",
       "                    75%     max  \n",
       "Year            2014.00  2018.0  \n",
       "original order  5782.25  6303.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 24. geting statistical overview of our table, it brings nthn since we have non numerical data\n",
    "summary=data.describe().T\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### TRYING DIFFERENT THINGS\n",
    "\n",
    "data1 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datetime\n",
    "#data1['year'] = pd.DatetimeIndex(data1['Year']).year\n",
    "#data1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_colnames(df):\n",
    "    '''Clean columns names when passing a pandas dataframe: params (df - dataframe)'''\n",
    "    col_clean = []\n",
    "    for col in df.columns:\n",
    "        col = col.strip().upper()\n",
    "        col_clean.append(col)\n",
    "        \n",
    "    df.columns = col_clean\n",
    "    return df.columns\n",
    "\n",
    "clean_colnames(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25. I will now try to extract months from Date column:\n",
    "#data1.sample(50)\n",
    "#data[\"Date\"].value_counts()\n",
    "# I notice that most (but not all) dates are in format dd-Month-yyyy, I will try to unify cells to one date format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOESN'T WORK:\n",
    "#data1['Date'] = pd.to_datetime(data1['Date'])\n",
    "#data1[\"Date\"].dt.strftime(\"%d/%b/%y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOESN'T WORK:\n",
    "#import numpy as np\n",
    "#import datetime\n",
    "#data1['Date'] = pd.to_datetime(data1['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOESN'T WORK:\n",
    "\"\"\"\n",
    "data2 = data1.copy()\n",
    "for row in data1['Date']:\n",
    "    if data1.Date.str.startswith('Reported'):\n",
    "            data2 = data1[\"Date\"].str[9,:]\n",
    "\n",
    "data2['Date'].value_counts()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOESN'T WORK:\n",
    "\"\"\"\n",
    "data2 = data1.copy()\n",
    "lista2 =[]\n",
    "for row in data1['Date']:\n",
    "    re_obj = re.sub(r'Reported ', '', row)\n",
    "    lista2.append(re_obj)\n",
    "data2['DateCorrected'] = lista2\n",
    "data2['DateCorrected'].value_counts()\n",
    "data2.head()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKS! :)\n",
    "# 1. extracting \"-aaa-\" from strings in Date\n",
    "# 2. cleaning \"-\"\n",
    "import re\n",
    "import numpy as np\n",
    "months_lst = []\n",
    "for row in data1['Date']:\n",
    "    #re_obj = ''.join(re.findall('[^\\d]',text)) #checking for letters (non numeric characters)\n",
    "    #re_obj = ''.join(re.findall('[A-Za-z]{4}\\-',row)).lower() #searching for months written differently than -aaa-\n",
    "    re_obj = ''.join(re.findall('\\-[A-Za-z]{3}\\-',row)).lower()\n",
    "    re_obj = re.sub('\\-','',re_obj)\n",
    "        \n",
    "        \n",
    "    #if re_obj == '':\n",
    "        #re_obj = np.nan\n",
    "\n",
    "    months_lst.append(re_obj)\n",
    "# adding a column Month:\n",
    "data1['Month'] = months_lst\n",
    "\n",
    "data1[\"Month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I notice that findall didnt fid a match with 57 rows, I will check them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.loc[data1['Month'] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I notice that many of them can be easily corrected with another findall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data1.copy()\n",
    "months_lst = []\n",
    "for row in data2['Date']:\n",
    "    re_obj = ''.join(re.findall('[A-Za-z]{3}\\-',row)).lower()\n",
    "    re_obj = re.sub('\\-','',re_obj)\n",
    "        \n",
    "        \n",
    "    #if re_obj == '':\n",
    "        #re_obj = np.nan\n",
    "\n",
    "    months_lst.append(re_obj)\n",
    "\n",
    "data2['Month'] = months_lst\n",
    "\n",
    "data2[\"Month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Great, I only have 17 unmatched rows and 3 matched, but need some cleaning\n",
    "# let s have a lok at these 17 unmatched rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.loc[data2['Month'] == \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3 = data2.loc[data2['Month'] == \"\"]\n",
    "data3.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another cleaning with findall:\n",
    "months_lst = []\n",
    "for row in data3['Date']:\n",
    "    re_obj = ''.join(re.findall('\\-[A-Za-z]{3}',row)).lower()\n",
    "    re_obj = re.sub('\\-','',re_obj)\n",
    "        \n",
    "        \n",
    "    #if re_obj == '':\n",
    "        #re_obj = np.nan\n",
    "\n",
    "    months_lst.append(re_obj)\n",
    "\n",
    "data3['Month'] = months_lst\n",
    "\n",
    "data3[\"Month\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"29-Nov2013\"\n",
    "\n",
    "re_obj = ''.join(re.findall('\\-[A-Za-z]{3}',text)).lower()\n",
    "re_obj = re.sub('\\-','',re_obj)\n",
    "print(re_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
